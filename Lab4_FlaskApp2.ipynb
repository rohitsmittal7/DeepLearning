{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Exp4_FlaskApp2.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yc88G3GYWZd4"
      },
      "source": [
        "# Flower Recognition "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JwQg1cnNWeys"
      },
      "source": [
        "### Importing necessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xan33_g1Wi11"
      },
      "source": [
        "# Ignore  the warnings\n",
        "import warnings\n",
        "warnings.filterwarnings('always')\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# data visualisation and manipulation\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import style\n",
        "import seaborn as sns\n",
        " \n",
        "#configure\n",
        "# sets matplotlib to inline and displays graphs below the corressponding cell.\n",
        "%matplotlib inline  \n",
        "style.use('fivethirtyeight')\n",
        "sns.set(style='whitegrid',color_codes=True)\n",
        "\n",
        "#model selection\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import accuracy_score,precision_score,recall_score,confusion_matrix,roc_curve,roc_auc_score\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "#preprocess.\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "#dl libraraies\n",
        "from keras import backend as K\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.optimizers import Adam,SGD,Adagrad,Adadelta,RMSprop\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "# specifically for cnn\n",
        "from keras.layers import Dropout, Flatten,Activation\n",
        "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
        " \n",
        "import tensorflow as tf\n",
        "import random as rn\n",
        "\n",
        "# specifically for manipulating zipped images and getting numpy arrays of pixel values of images.\n",
        "import cv2                  \n",
        "import numpy as np  \n",
        "from tqdm import tqdm\n",
        "import os                   \n",
        "from random import shuffle  \n",
        "from zipfile import ZipFile\n",
        "from PIL import Image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VTbKCTFncWFl"
      },
      "source": [
        "!wget http://upscfever.com/datasets/flowers-new.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1J-aYI9BiJyh"
      },
      "source": [
        "!unzip flowers-new.zip\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-r6UyPMlW_3Q"
      },
      "source": [
        "### Making the functions to get the training and validation set from the Images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UQ5sDzfMXBeb"
      },
      "source": [
        "X=[]\n",
        "Z=[]\n",
        "IMG_SIZE=150\n",
        "FLOWER_DAISY_DIR='flowers/daisy'\n",
        "FLOWER_SUNFLOWER_DIR='flowers/sunflower'\n",
        "FLOWER_TULIP_DIR='flowers/tulip'\n",
        "FLOWER_DANDI_DIR='flowers/dandelion'\n",
        "FLOWER_ROSE_DIR='flowers/rose'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KW16fH1s2Puw"
      },
      "source": [
        "flower_dirs = [FLOWER_DAISY_DIR, FLOWER_SUNFLOWER_DIR, FLOWER_TULIP_DIR, FLOWER_DANDI_DIR, FLOWER_ROSE_DIR]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u-KU1xiovJuU"
      },
      "source": [
        "flowers = ['Daisy', 'Sunflower', 'Tulip', 'Dandelion', 'Rose']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NK9syL9JinMi"
      },
      "source": [
        "def generate_images(flower, DIR, num=10):\n",
        "  for img in tqdm(os.listdir(DIR)):\n",
        "    img = cv2.imread(DIR + '/' + img)\n",
        "    img = img.reshape((1,) + img.shape)\n",
        "\n",
        "    gen_datagen = ImageDataGenerator(\n",
        "          rotation_range=90,  \n",
        "          zoom_range = 0.3, \n",
        "          width_shift_range=0.2,\n",
        "          height_shift_range=0.2,\n",
        "          horizontal_flip=True,\n",
        "          vertical_flip=True,\n",
        "          brightness_range=[0.5,1.5],\n",
        "          shear_range=0.2\n",
        "    )\n",
        "\n",
        "    for idx, image_save in enumerate((gen_datagen.flow(img, \n",
        "                                                      batch_size=1, \n",
        "                                                      save_to_dir = DIR + '/', save_prefix=flower,\n",
        "                                                      save_format='jpg'))):\n",
        "      if idx == 30:\n",
        "        break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VXMYoDjiZ4sH"
      },
      "source": [
        "for flower, flower_dir in zip(flowers, flower_dirs):\n",
        "  generate_images(flower, flower_dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "az4-Q7fXbTJh"
      },
      "source": [
        "len(os.listdir(FLOWER_DAISY_DIR))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aJKgnZIEXI67"
      },
      "source": [
        "def make_train_data(flower_type,DIR):\n",
        "    for img in os.listdir(DIR):\n",
        "        \n",
        "        path = os.path.join(DIR,img)\n",
        "        img = cv2.imread(path,cv2.IMREAD_COLOR)\n",
        "        img = cv2.resize(img, (IMG_SIZE,IMG_SIZE))\n",
        "        \n",
        "        X.append(np.array(img))\n",
        "        Z.append(str(flower_type))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8A_qFRCEjwBM"
      },
      "source": [
        "for flower, flower_dir in zip(flowers, flower_dirs):\n",
        "  make_train_data(flower, flower_dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "00QAjJwVjyYp"
      },
      "source": [
        "for flower_dir in flower_dirs:\n",
        "  print(str(len(os.listdir(flower_dir))) + flower_dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yXh1hrrZcxU-"
      },
      "source": [
        "fig, ax = plt.subplots(5,5)\n",
        "fig.set_size_inches(9,9)\n",
        "\n",
        "for i in range(5):\n",
        "  for j in range(5):\n",
        "\n",
        "    ax[i][j].set_xticks([])\n",
        "    ax[i][j].set_yticks([])\n",
        "\n",
        "    l = rn.randint(0,len(Z))\n",
        "    ax[i][j].imshow(X[l])\n",
        "    ax[i][j].title.set_text('Flower: '+ Z[l])\n",
        "    \n",
        "plt.tight_layout()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OklVJmJj0zYK"
      },
      "source": [
        "len(X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6jvgN_3V05M9"
      },
      "source": [
        "len(Z)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mAYo_ZB3XTDv"
      },
      "source": [
        "### Label Encoding the Y array (i.e. Daisy->0, Rose->1 etc...) & then One Hot Encoding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vDeGvCQdXVFf"
      },
      "source": [
        "le=LabelEncoder()\n",
        "Y=le.fit_transform(Z)\n",
        "Y=to_categorical(Y,5)\n",
        "X=np.array(X)\n",
        "X=X/255"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IGyqUZwWXaEt"
      },
      "source": [
        "### Splitting into Training and Validation Sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9gOIt4kvXgtR"
      },
      "source": [
        "x_train,x_test,y_train,y_test=train_test_split(X,Y,test_size=0.25,random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "voJEFrZDXurs"
      },
      "source": [
        "### Setting the Random Seeds"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UW62vt2SXxpf"
      },
      "source": [
        "np.random.seed(42)\n",
        "rn.seed(42)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v9xQPDv7YOY4"
      },
      "source": [
        "### Building the ANN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NPYzF30nYOY4"
      },
      "source": [
        "import tensorflow as tf \n",
        "from tensorflow import keras \n",
        "import matplotlib.pyplot as plt \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mb13euYiYOY5"
      },
      "source": [
        "model = keras.Sequential([keras.layers.Flatten(input_shape=(150,150,3)),\n",
        "                          keras.layers.Dense(128,activation = tf.nn.relu, kernel_regularizer=tf.keras.regularizers.l2(0.001)),\n",
        "                          keras.layers.Dense(64,activation = tf.nn.relu,kernel_regularizer=tf.keras.regularizers.l2(0.001)),\n",
        "                          keras.layers.Dense(32,activation = tf.nn.relu,kernel_regularizer=tf.keras.regularizers.l2(0.001)),\n",
        "                          keras.layers.Dense(5)])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ZSOpc0ZYOY5"
      },
      "source": [
        "model.compile(optimizer = tf.keras.optimizers.Adam(),\n",
        "              loss = tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ige7pXeVYOY7"
      },
      "source": [
        "### Building ANN Model "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OuWcSkY_5GMv"
      },
      "source": [
        "from keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint\n",
        "\n",
        "rd = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5, verbose=1, mode='auto', min_delta=0.0001, cooldown=0, min_lr=0)\n",
        "es = EarlyStopping(monitor='val_loss', min_delta=0, patience=55, verbose=1, mode='auto')\n",
        "filepath='regularized_weight_{epoch:02d}_{val_loss:.2f}.h5'\n",
        "mc = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='auto')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qSwsLw-PYOY7"
      },
      "source": [
        "history = model.fit(x_train,y_train, batch_size=100, validation_split=0.2, epochs = 100, verbose = 2, callbacks=[rd, es, mc])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xuHUFw3geeDE"
      },
      "source": [
        "pred = model.evaluate(x_test, y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tbIeFF977J7p"
      },
      "source": [
        "#Add softmax to get predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BapLljqA7MzD"
      },
      "source": [
        "final_model = tf.keras.Sequential([\n",
        "                                   model,\n",
        "                                   tf.keras.layers.Softmax()\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ga7kEHzXYOY8"
      },
      "source": [
        "predictions = final_model.predict_classes(x_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "71u5lxvCYOY-"
      },
      "source": [
        "### Saving Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "59WC6CvnYOY-"
      },
      "source": [
        "# save the model to disk\n",
        "final_model.save('final_model2.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1-5RFM1EYOY-"
      },
      "source": [
        "### Loading Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rcer3YpRYOY-"
      },
      "source": [
        "from tensorflow import keras\n",
        "model = keras.models.load_model('/content/regularized_weight_40_1.39.h5')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-F9Pd5YOYOY_"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_X2j_3Axh3LQ"
      },
      "source": [
        "#Deployment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Subl3y3jh4aS"
      },
      "source": [
        "!pip install flask gevent requests pillow"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sWbggV1HiIRn"
      },
      "source": [
        "Creat a file ProcFile"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jntXbq6SiKLp"
      },
      "source": [
        "procfile = 'web: gunicorn app:app'\n",
        "procfiles= open(\"/content/Procfile\",\"w\")\n",
        "procfiles.write(procfile)\n",
        "procfiles.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c1A_HR9WiU2M"
      },
      "source": [
        "#Install flask and ngrok"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GO41Vpx0iX0h"
      },
      "source": [
        "!pip install flask-ngrok\n",
        "from flask_ngrok import run_with_ngrok\n",
        "from flask import Flask"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CWpMsr7Eimfg"
      },
      "source": [
        "#Webpage"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q86Pm5i8inkN"
      },
      "source": [
        "a = '''\n",
        "<!doctype html>\n",
        "<html lang=\"en\">\n",
        "<head>\n",
        "<title>My flower recognizer</title>\n",
        "</head> \n",
        "  <body>\n",
        " \n",
        "          <h3>Image Recognition Server</h3><br/>\n",
        "       \n",
        "      <form action=\"\" method=\"post\" enctype=multipart/form-data>\n",
        "        <input type=file name=\"flowers\"><br/>\n",
        "        \n",
        "        <p>daisy = 0</p><br/>\n",
        "        <p>dandelion = 1</p><br/>\n",
        "        <p>rose = 2</p><br/>\n",
        "        <p>sunflower = 3</p><br/>\n",
        "        <p>tulip = 4</p><br/>\n",
        "        <p>Enter flower number in text box</p><br/>\n",
        "        <input type=text name=\"flower_name\">\n",
        "\n",
        "        <input type=submit value=Upload>\n",
        "    </form>\n",
        "    {{label}}  \n",
        "     \n",
        "  </body>\n",
        "  </html>\n",
        "  '''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8xtT50rRivur"
      },
      "source": [
        "!mkdir '/content/templates'\n",
        "!mkdir '/content/uploads'\n",
        "!mkdir '/content/uploads/daisy'\n",
        "!mkdir '/content/uploads/dandelion'\n",
        "!mkdir '/content/uploads/rose'\n",
        "!mkdir '/content/uploads/sunflower'\n",
        "!mkdir '/content/uploads/tulip'\n",
        "\n",
        "Html_file = open(\"/content/templates/index.html\", \"w\")\n",
        "Html_file.write(a)\n",
        "Html_file.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uWK13ODsj_OW"
      },
      "source": [
        "#Deploy model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KHwCxp36j7bh"
      },
      "source": [
        "import os\n",
        "from flask import Flask, render_template, request\n",
        "from keras.preprocessing import image\n",
        "from keras.preprocessing.image import load_img, img_to_array\n",
        "\n",
        "app = Flask(__name__)\n",
        "run_with_ngrok(app)\n",
        "app.config['UPLOADS'] = 'uploads'\n",
        "\n",
        "\n",
        "def load_mymodel():\n",
        "    global mymodel\n",
        "    mymodel = keras.models.load_model('/content/regularized_weight_40_1.39.h5')\n",
        "    final_model = tf.keras.Sequential([\n",
        "                                   mymodel,\n",
        "                                   tf.keras.layers.Softmax()\n",
        "    ])\n",
        "    \n",
        "\n",
        "@app.route('/')\n",
        "def home():\n",
        "    return render_template('index.html')\n",
        "\n",
        "def predictions(file):\n",
        "    img = image.load_img(file, target_size=(150,150), color_mode=\"rgb\")\n",
        "    img = img_to_array(img)\n",
        "    img = np.expand_dims(img, axis=0)\n",
        "    ans = final_model.predict_classes(img)\n",
        "    return ans\n",
        "\n",
        "\n",
        "@app.route('/', methods=['POST'])\n",
        "def upload_files():\n",
        "    file = request.files['flowers']\n",
        "    flowerslabels = request.form['flower_name']\n",
        "    print(type(flowerslabels))\n",
        "    if int(flowerslabels) == 0:\n",
        "      flowerslabels = 'daisy'\n",
        "      filepath = os.path.join(app.config['UPLOADS'], flowerslabels, file.filename)\n",
        "      file.save(filepath)\n",
        "    elif int(flowerslabels) == 1:\n",
        "      flowerslabels = 'dandelion'\n",
        "      filepath = os.path.join(app.config['UPLOADS'], flowerslabels, file.filename)\n",
        "      file.save(filepath)\n",
        "    elif int(flowerslabels) == 2:\n",
        "      flowerslabels = 'rose'\n",
        "      filepath = os.path.join(app.config['UPLOADS'], flowerslabels, file.filename)\n",
        "      file.save(filepath)\n",
        "    elif int(flowerslabels) == 3:\n",
        "      flowerslabels = 'sunflower'\n",
        "      filepath = os.path.join(app.config['UPLOADS'], flowerslabels, file.filename)\n",
        "      file.save(filepath)\n",
        "    else:\n",
        "      flowerslabels = 'tulip'\n",
        "      filepath = os.path.join(app.config['UPLOADS'], flowerslabels, file.filename)\n",
        "      file.save(filepath)\n",
        "\n",
        "\n",
        "\n",
        "    output = predictions(filepath)\n",
        "\n",
        "    if output.astype('int32') == 0:\n",
        "      output = 'daisy'\n",
        "    elif output.astype('int32') == 1:\n",
        "      output = 'dandelion'\n",
        "    elif output.astype('int32') == 2:\n",
        "      output = 'rose'\n",
        "    elif output.astype('int32') == 3:\n",
        "      output = 'sunflower'\n",
        "    else:\n",
        "      output = 'tulip'\n",
        "\n",
        "    return render_template('index.html', label=output)\n",
        "\n",
        "\n",
        "\n",
        "if __name__=='__main__':\n",
        "    load_mymodel()\n",
        "    app.run()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t_foggstkA8D"
      },
      "source": [
        "#Data augmentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oP2R9Ou5G5cf"
      },
      "source": [
        "#code part 1\n",
        "from bs4 import BeautifulSoup\n",
        "import numpy as np\n",
        "import requests\n",
        "import cv2\n",
        "import PIL.Image\n",
        "import urllib\n",
        "\n",
        "cats_page = requests.get(\"http://www.image-net.org/api/text/imagenet.synset.geturls?wnid=n11712282\")# synset\n",
        "print(cats_page.content)\n",
        "cats_soup = BeautifulSoup(cats_page.content, 'html.parser')#puts the content of the website into the soup variable, each url on a different line\n",
        "\n",
        "\n",
        "dogs_page = requests.get(\"http://www.image-net.org/api/text/imagenet.synset.geturls?wnid=n12024176\")# synset\n",
        "print(dogs_page.content)\n",
        "dogs_soup = BeautifulSoup(dogs_page.content, 'html.parser')#puts the content of the website into the soup variable, each url on a different line\n",
        "\n",
        "dogs_page1 = requests.get(\"http://www.image-net.org/api/text/imagenet.synset.geturls?wnid=n11971783\")# synset\n",
        "print(dogs_page1.content)\n",
        "dogs_soup1 = BeautifulSoup(dogs_page1.content, 'html.parser')#puts the content of the website into the soup variable, each url on a different line\n",
        "dogs_page2 = requests.get(\"http://www.image-net.org/api/text/imagenet.synset.geturls?wnid=n11980318\")# synset\n",
        "print(dogs_page2.content)\n",
        "dogs_soup2 = BeautifulSoup(dogs_page2.content, 'html.parser')#puts the content of the website into the soup variable, each url on a different line\n",
        "\n",
        "\n",
        "\n",
        "#code part 2\n",
        "cats_str_soup=str(cats_soup)#convert soup to string so it can be split\n",
        "type(cats_str_soup)\n",
        "cats_split_urls=cats_str_soup.split('\\r\\n')#split so each url is a different possition on a list\n",
        "print(len(cats_split_urls))#print the length of the list so you know how many urls you have\n",
        "\n",
        "#code part 2.2\n",
        "dogs_str_soup=str(dogs_soup)#convert soup to string so it can be split\n",
        "type(dogs_str_soup)\n",
        "dogs_split_urls=dogs_str_soup.split('\\r\\n')#split so each url is a different possition on a list\n",
        "print(len(dogs_split_urls))\n",
        "\n",
        "dogs_str_soup1=str(dogs_soup1)#convert soup to string so it can be split\n",
        "type(dogs_str_soup1)\n",
        "dogs_split_urls1=dogs_str_soup1.split('\\r\\n')#split so each url is a different possition on a list\n",
        "print(len(dogs_split_urls1))\n",
        "\n",
        "dogs_str_soup2=str(dogs_soup2)#convert soup to string so it can be split\n",
        "type(dogs_str_soup2)\n",
        "dogs_split_urls2=dogs_str_soup2.split('\\r\\n')#split so each url is a different possition on a list\n",
        "print(len(dogs_split_urls2))\n",
        "\n",
        "\n",
        "img_rows, img_cols = 150, 150 #number of rows and columns to convert the images to\n",
        "input_shape = (img_rows, img_cols, 3)#format to store the images (rows, columns,channels) called channels last\n",
        "\n",
        "def url_to_image(url):\n",
        "\t# download the image, convert it to a NumPy array, and then read\n",
        "\t# it into OpenCV format\n",
        "\tresp = urllib.request.urlopen(url)\n",
        "\timage = np.asarray(bytearray(resp.read()), dtype=\"uint8\")\n",
        "\timage = cv2.imdecode(image, cv2.IMREAD_COLOR)\n",
        " \n",
        "\t# return the image\n",
        "\treturn image\n",
        "\n",
        "n_of_training_images=20#the number of training images to use\n",
        "for progress in range(n_of_training_images):#store all the images on a directory\n",
        " \n",
        "    if(progress%20==0):\n",
        "        print(progress)\n",
        "    if not cats_split_urls[progress] == None:\n",
        "      try:\n",
        "        I = url_to_image(cats_split_urls[progress])\n",
        "        if (len(I.shape))==3: #check if the image has width, length and channels\n",
        "          save_path = '/content/uploads/tulip/tulip_'+str(progress)+'.jpg'#create a name of each image\n",
        "          cv2.imwrite(save_path,I)\n",
        "\n",
        "      except:\n",
        "        None\n",
        "\n",
        "for progress in range(n_of_training_images):#store all the images on a directory\n",
        "  \n",
        "    if(progress%20==0):\n",
        "        print(progress)\n",
        "    if not dogs_split_urls[progress] == None:\n",
        "      try:\n",
        "        I = url_to_image(dogs_split_urls[progress])\n",
        "        if (len(I.shape))==3: #check if the image has width, length and channels\n",
        "          save_path = '/content/uploads/dandelion/daisy2_'+str(progress)+'.jpg'#create a name of each image\n",
        "          cv2.imwrite(save_path,I)\n",
        "\n",
        "      except:\n",
        "        None\n",
        "\n",
        "\n",
        "for progress in range(n_of_training_images):#store all the images on a directory\n",
        "  \n",
        "    if(progress%20==0):\n",
        "        print(progress)\n",
        "    if not dogs_split_urls1[progress] == None:\n",
        "      try:\n",
        "        I = url_to_image(dogs_split_urls1[progress])\n",
        "        if (len(I.shape))==3: #check if the image has width, length and channels\n",
        "          save_path = '/content/uploads/daisy/daisy3_'+str(progress)+'.jpg'#create a name of each image\n",
        "          cv2.imwrite(save_path,I)\n",
        "\n",
        "      except:\n",
        "        None\n",
        "\n",
        "\n",
        "for progress in range(n_of_training_images):#store all the images on a directory\n",
        "  \n",
        "    if(progress%20==0):\n",
        "        print(progress)\n",
        "    if not dogs_split_urls2[progress] == None:\n",
        "      try:\n",
        "        I = url_to_image(dogs_split_urls2[progress])\n",
        "        if (len(I.shape))==3: #check if the image has width, length and channels\n",
        "          save_path = '/content/uploads/daisy/daisy4_'+str(progress)+'.jpg'#create a name of each image\n",
        "          cv2.imwrite(save_path,I)\n",
        "\n",
        "      except:\n",
        "        None"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9a4H6yowr-RJ"
      },
      "source": [
        "Xdevt=[]\n",
        "Zdevt=[]\n",
        "IMG_SIZE=150\n",
        "FLOWER_DAISY_DIR='uploads/daisy'\n",
        "FLOWER_SUNFLOWER_DIR='uploads/sunflower'\n",
        "FLOWER_TULIP_DIR='uploads/tulip'\n",
        "FLOWER_DANDI_DIR='uploads/dandelion'\n",
        "FLOWER_ROSE_DIR='uploads/rose'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y1ZFQiTBr-RN"
      },
      "source": [
        "flower_dirs = [FLOWER_DAISY_DIR, FLOWER_SUNFLOWER_DIR, FLOWER_TULIP_DIR, FLOWER_DANDI_DIR, FLOWER_ROSE_DIR]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FGJQnoXRr-RR"
      },
      "source": [
        "flowers = ['Daisy', 'Sunflower', 'Tulip', 'Dandelion', 'Rose']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KiyxG9m-r-RT"
      },
      "source": [
        "def generate_images(flower, DIR, num=10):\n",
        "  for img in tqdm(os.listdir(DIR)):\n",
        "    img = cv2.imread(DIR + '/' + img)\n",
        "    img = img.reshape((1,) + img.shape)\n",
        "\n",
        "    gen_datagen = ImageDataGenerator(\n",
        "          rotation_range=90,  \n",
        "          zoom_range = 0.3, \n",
        "          width_shift_range=0.2,\n",
        "          height_shift_range=0.2,\n",
        "          horizontal_flip=True,\n",
        "          vertical_flip=True,\n",
        "          brightness_range=[0.5,1.5],\n",
        "          shear_range=0.2\n",
        "    )\n",
        "\n",
        "    for idx, image_save in enumerate((gen_datagen.flow(img, \n",
        "                                                      batch_size=1, \n",
        "                                                      save_to_dir = DIR + '/', save_prefix=flower,\n",
        "                                                      save_format='jpg'))):\n",
        "      if idx == 30:\n",
        "        break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MBeTHiICr-RW"
      },
      "source": [
        "for flower, flower_dir in zip(flowers, flower_dirs):\n",
        "  generate_images(flower, flower_dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hnfRfjAJr-Ra"
      },
      "source": [
        "len(os.listdir(FLOWER_DAISY_DIR))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0js_ivAVr-Rd"
      },
      "source": [
        "def make_train_data(flower_type,DIR):\n",
        "    for img in os.listdir(DIR):\n",
        "        \n",
        "        path = os.path.join(DIR,img)\n",
        "        img = cv2.imread(path,cv2.IMREAD_COLOR)\n",
        "        img = cv2.resize(img, (IMG_SIZE,IMG_SIZE))\n",
        "        \n",
        "        X.append(np.array(img))\n",
        "        Z.append(str(flower_type))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "It7NvRk4r-Rf"
      },
      "source": [
        "for flower, flower_dir in zip(flowers, flower_dirs):\n",
        "  make_train_data(flower, flower_dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2YIsOSL7r-Rj"
      },
      "source": [
        "for flower_dir in flower_dirs:\n",
        "  print(str(len(os.listdir(flower_dir))) + flower_dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "26XhRWoer-Rm"
      },
      "source": [
        "fig, ax = plt.subplots(5,5)\n",
        "fig.set_size_inches(9,9)\n",
        "\n",
        "for i in range(5):\n",
        "  for j in range(5):\n",
        "\n",
        "    ax[i][j].set_xticks([])\n",
        "    ax[i][j].set_yticks([])\n",
        "\n",
        "    l = rn.randint(0,len(Z))\n",
        "    ax[i][j].imshow(X[l])\n",
        "    ax[i][j].title.set_text('Flower: '+ Z[l])\n",
        "    \n",
        "plt.tight_layout()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yb4jWwEjr-Rq"
      },
      "source": [
        "len(Xdevt)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8FAVdipur-Rr"
      },
      "source": [
        "len(Zdevt)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N6CzWRWHr-Rt"
      },
      "source": [
        "### Label Encoding the Y array (i.e. Daisy->0, Rose->1 etc...) & then One Hot Encoding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KQ8YlorZr-Rv"
      },
      "source": [
        "le=LabelEncoder()\n",
        "Ydevt=le.fit_transform(Zdevt)\n",
        "Ydevt=to_categorical(Ydevt,5)\n",
        "Xdevt=np.array(Xdevt)\n",
        "Xdevt=Xdevt/255"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eihsa07yr-Rw"
      },
      "source": [
        "### Splitting into Training and Validation Sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_HEgRSXEr-Rx"
      },
      "source": [
        "xdevt_train,xdevt_test,ydevt_train,ydevt_test=train_test_split(Xdevt,Ydevt,test_size=0.25,random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}